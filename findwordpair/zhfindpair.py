import jieba
import re
import pandas as pd
from langconv import *
import logging
from tqdm import tqdm
import numpy as np
import os
import time

# é˜²æ­¢jiebaæ‰“å°æ—¥å¿—
jieba.setLogLevel(logging.INFO)

def getstopwords():
    with open("../stopwords-zh/ä¸­æ–‡åœç”¨è¯è¡¨.txt", 'r', encoding='utf-8') as f:
        stops = f.read()
        return stops.split('\n')

def loadtxt(filename):
    # ç­›é€‰ç‰¹å®šæ–‡æœ¬
    sample = pd.read_excel(filename)
    sample = sample[sample["RTed"].isna()]
    sample.reset_index()
    sample = sample[sample['created_at'] >= pd.datetime(2019, 6, 1)]
    text = sample["text"]

    return text


def preprocess(text):
    text = format_str(text)

    # ç¹ä½“åˆ°ç®€ä½“
    text = converter.convert(text)

    # åˆ†è¯
    cut_words = list(jieba.cut(text))

    # é™¤å»åœç”¨è¯
    clean_text = [w for w in cut_words if not w in stopwords]
    return clean_text



def pmi(dicts, doc):
    relate = []
    r_dicts = {}
    total = len(doc)
    words = dicts.keys()
    for w1 in tqdm(words):
        p1 = dicts[w1] / total
        for w2 in words:
            if w1 is w2:
                continue
            else:
                p2 = dicts[w2] / total
                p3 = cal_pxy(w1, w2, doc) / total
                if p3 == 0:
                    continue
                r = f(p1, p2, p3)
                relate.append((w2, r))
        r_dicts[w1] = sorted(relate, key=lambda item:item[1], reverse=True)[:10]
        relate = []
    return r_dicts


def cal_pxy(w1, w2, docs):
    pair = {w1, w2}
    appear = 0
    for item in docs:
        word = item
        if pair.issubset(set(word)):
            appear += 1
    return appear


def f(px, py, pxy):
    return np.log(pxy/(px*py))


def writemss(filename, sorteddict, r_dicts, name, text):
    with open(filename+".txt", 'w+', encoding='utf-8') as f:
        f.write("å‘æ–‡è€…: {:^18} ä»2019/6/1æ‰€å‘æ¨æ–‡æ•°: {}\n".format(name, len(text)))
        for w, times in sorteddict.items():
            f.write("å…³é”®å­—: {:<12} å‡ºç°æ¬¡æ•°: {}\n".format(w, times))
            for rw, v in r_dicts[w][:5]:
                f.write("é«˜è”ç³»è¯å¯¹: {:<12} è”ç³»å€¼:{:.2f}\n".format(rw, v))


def main(text, user, dir):
    dicts = {}
    prewords = []
    for word in tqdm(text):
        word = preprocess(word)
        prewords.append(word)
        for w in word:
            dicts[w] = dicts.get(w, 0) + 1
    sorteddict = dict(sorted(dicts.items(), key=lambda item:item[1], reverse=True)[:50])
    r_dicts = pmi(sorteddict, prewords)
    writemss(dir, sorteddict, r_dicts, user, text)


def format_str(sentence):
    pattern1 = r'\[.*?\]'
    pattern2 = re.compile(r'[^\u4e00-\u9fa5]')
    line1 = re.sub(pattern1, '', sentence)
    line2 = re.sub(pattern2, '', line1)
    new_sentence = ''.join(line2.split())  # å»é™¤ç©ºç™½
    return new_sentence


if __name__ == '__main__':
    converter = Converter("zh-hans")
    stopwords = getstopwords()
    newlist = ['æœˆ', 'æ—¥', 'æƒ³', 'ğŸ˜‚ğŸ˜‚ğŸ˜‚']
    stopwords.extend(newlist)
    process_dir = "../wordget/zhprocess"
    data_dir = "../wordget/zh"
    if not os.path.exists(process_dir):
        os.mkdir(process_dir)
    for dir in os.listdir(data_dir):
        tweet_dir = os.path.join(data_dir, dir)
        tweet = loadtxt(tweet_dir)
        nickname = dir.split('-')[1]
        print("load user {}".format(nickname))
        time.sleep(0.1)
        save_path = os.path.join(process_dir, nickname)
        main(tweet, nickname, save_path)